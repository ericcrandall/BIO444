---
title: 
- <h1>Mutation Models</h1>
date: <center>`r format(Sys.time(), '%d %B, %Y')`</center>
bibliography: ../TPG.bib
csl: ../genetics.csl.txt
output:
  html_document:
    theme:  paper
    keep_md: no
    toc: yes
    toc_depth: 5
    code_fold: show
---

```{r,echo=FALSE}
library(Matrix)
library(phangorn)
```

## Mutation Models

We now need to think a little bit more about mutation as an evolutionary process.  In particular, and for the first time, we need to really think about genes as DNA sequences.  The data we have available to us are (usually) two or more contemporary sequences, and we can determine the number of *differences* between them.  However, what we are interested in as a process is the number *substitutions* that have occurred giving rise to those differences.  To get at that question, we need to think in more detail about what a sequence is.  In brief

1.  It's a set of k **sites**
2.  Each site of a particular sequence can be occupied by one of the four bases - A, G, C, or T.
3.  Mutation can result in a particular site of a sequence changing (for example from A ->G or C -> T.
4.  Two of the bases are *purines* (A and G) and the other are *pyrimidines* (C and T), so mutations can be either *transitions* (purines <-> purines or pyrimidines <-> pyrimidines) or *transversions* (purines <--> pyrimidines).  
5.  If we are dealing with protein coding sequences, we need to consider the effect of the mutation on the encoded protein (does it result in an amino acid change or not)?

### The basic model

For our purposes, we're going to assume that at a given time, the probability of a given mutation is constant and is the same for each position being considered.  Thus, we can think of there being a stable *Transition matrix* conisting of the probabilities of all possible state changes (no change, transition, transversion).  And if our model is "time-reversible" then p(A - > G) is the same as p(G ->A) and the matrix is symmetric.

![Figure 1](https://dl.dropboxusercontent.com/u/9752688/PopGenWithR/images/MutationMatrix.png)

### The Jukes Cantor Model

We will start with the simplest model.  In it we assume that there are four possible states at each position (A, G, C, and T), and that there is some rate &alpha; at which one base mutates to one of the other three.  Thus, for example, if we start with an A at time t, at time t+1, the probability of no mutation coccuring would be 

\(p_{a,a}= 1-3\alpha\) (remembering that mutation occurs to each of three bases with rate &alpha;)

and \(p_{a,c}\), for example, would be &alpha;

For simplicity's sake for the moment, let's set alpha equal to one, so that we are using substitution rate as our time unit.  We can also think that there are three ways we can lose a particular base (as represented on the diagonal) and one way we can gain it (the other elements of the matrix.  We can thus start with a matrix Q, which shows the *relative rates* of all possible transitions:

```{r}
Q1 <-matrix(c(-3,1,1,1,1,-3,1,1,1,1,-3,1,1,1,1,-3), nrow=4)
Q1
```

Where the rows and columns are A, G, C, and T.  This is usually then normalized in such a way that all of the possible transitions made by a base add to zero.  This will then allow us to express our transition probability in terms of substitutions per site (or genetic distance).

```{r}
Q2 <-Q1/3
Q2

```

This is what is known as the "instantaneous transition rate matrix".  But what we need is a "transition probability matrix".  It turns out that this is pretty easy to get (at least with a computer) - we simply exponentiate our rate matrix:

```{r}
Qt <-expm(Q2)
Qt
```

Note that the rows and columns of this matrix sum to one.  This is as it should be - if we refer back to our original matrix above (Figure 1), we realize that the first each row can be thought of as the fate of a particular base, and so the probability that it will be A, G, C, or T after one generation must be one.

Down the road, we will return to the elements of this matrix and look at what they mean with respect to relating number of substitutions to observed sequence differences, but for now, let's ask the following question:  Given that there is a position that is fixed for A, what would the base frequencies be after one time unit?  To do that, we simply use matrix multiplication to calculate the new base frequencies

```{r}
b <-c(1,0,0,0) #initial frequencies of A, G, C, and T.
```
Now, by implementing the following code repeatedly, we can see what happens with each time unit:
```{r}
b <-b%*%Qt # multiply by transition matrix
b
```

And we see that the frequencies of the four bases rapidly converge on 0.25.  

Another way we can look at this is  looking at both the transition probability A->A (i. e. no mutation) at that position and that of a change (A ->C) as the number of substitutions increases

```{r}
t <-seq(0.1,2,.1)
Q.time <-lapply(t, function (x) expm(Q2*x))
pAA <-sapply(Q.time,function(x) x[1,1])
pAC <-sapply(Q.time,function(x) x[1,2])
p.mat <-cbind(pAA,pAC)
matplot(t,p.mat,type="l",lty=1,xlab="Genetic Distance (ut)",ylab="Transition Probability",main="Jukes-Cantor Model")
abline(h=.25,lty=2)
text(1.5,.5,"A ->A")
text(1.5,.1,"A->C",col="red")
```

What we see is that both lines assymptotically approach .25, reflective of the fact that, under our model, are equally probable to occupy a position, regardless of what the starting state was.

### Differentiating between transitions and transversions - the K80 Model

What we have done so far is obviously simplistic - as noted at the outset, other factors are involved as well.  One of those is that it is well established that transition mutations occur more frequently than transversions.  In the following, k is a rate associated with transitions and &beta; with transversions:

![](https://dl.dropboxusercontent.com/u/9752688/PopGenWithR/images/K80.png)

If we set k to 4 and &beta; to 1/(2+k), then we can get  our transition rate matrix:

```{r}
k=4
b=1/(2+k)
Qk <- b*matrix(c(-2-k,1,k,1,1,-2-k,1,k,k,1,-2-k,1,1,k,1,-2-k),ncol=4)
Qk
```

And we note that the rate of transversions is lower than that of transitions.  And this can be converted to a probability matrix by expontiating

```{r}
Qk.t <-expm(Qk)
Qk.t
```

And we can do similar manipulations (code not shown) as before, plotting three transition probabilities this time - no change (A->A) a transition (A->G) and a transversion (A_>C)

```{r}
Qk.t <-lapply(t, function (x) expm(Qk*x))
pAA <-sapply(Qk.t,function(x) x[1,1])
pAC <-sapply(Qk.t,function(x) x[1,2])
pAG <-sapply(Qk.t, function(x) x[1,3])
p.mat <-cbind(pAA,pAC,pAG)
matplot(t,p.mat,type="l",lty=1,xlab="Genetic Distance (ut)",ylab="Transition Probability",main="K80 Model")
abline(h=.25,lty=2)
text(1.6,.5,"A ->A",cex=.8)
text(1.6,.1,"A->T",col="red",cex=.8)
text(0.9,0.18,"A-G",col="green",cex=.8)
```

So we see that the transition probabilities are higher than the transversion, although given sufficient time, once again all frequencies converge on 0.25.

### Choosing models

There are three additional models that are commonly used in modeling the evolutionary process, and each one of them has even more twists that can be specified.  

2.  The Felsenstein model, which incorporates base composition
3.  The HKY model combines both base composition and transition-transversion differences, along with variable rates, into what is at present the most widely used model.
4.  The Generalized Time-Reversible model (GTR),which incorporates separate parameters for each different transition or transversion.

So which should we use?  There are two possible approaches

1.  Keep it simple.  As the models become more complex, there are more parameters that must be estimated from the data.  This is risky - there may simply not be enough data to come up with accurate assessments of each.
2.  Compare the different models.  Here, we won't go into great detail, but there is a procedure that does that, which is implemented in the phangorn package of R.  An example, We will look at a small simulated DNA sequence data set:

```{r}
dat <-read.FASTA("./BeastDemo/demo1.fasta")
dat.phy <-phyDat(dat)

dat.mt <-modelTest(dat.phy,G=FALSE,I=FALSE)

dat.mt[with(dat.mt,order(dat.mt$BIC)),]
```

Here, the models are listed from the best fit to the worst, and we find out that, for these data, the Jukes and Cantor model works fine.  But in fact that's the model that was used to simulate the data, so that is no surprise.  What if we use some real data?  We can use some mitochondrial DNA sequences from fur seals [@Hoffman2011] as an example.

```{r}
data(furseals)
fur.phy <-phyDat(fur.dat)
fur.mt <-modelTest(fur.phy,G=FALSE,I=FALSE)
fur.mt[with(fur.mt,order(fur.mt$BIC)),]

```

Now we see that it is the HKY model that best fits the data, while the JC model is the worst.  Again, this is as we expected, as the HKY model was explicitly developed to be applicable to mammalian mitochondrial DNA.

### Summary

From what we have covered in this chapter, there are a number of points that need to be re-emphasized.

1.  Mutation is random with respect to mutation
2.  The fate of most new mutations is that they are lost.
3.  Those that are not lost are what underly observed sequence differences
4.  The challenge for the evolutionary geneticist is to infer the number of substitutions that occur based on observed sequence differences.

But suppose we can estimate rates.  Could we then use sequence data to make inferences about evolutionary history?  The short answer is that we can, but before doing so we need to explore the dynamics of allele frequencies and gene genealogies in finite populations.