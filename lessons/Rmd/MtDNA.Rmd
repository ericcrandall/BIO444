---
title: <center>Mitochondrial DNA and Haplotype Networks</center>
author: <center></center>
date: <center>`r format(Sys.Date(),format="%B %d %Y")`</center>
output: 
    html_document:
       css: Chapter.css
       toc: yes
       toc_depth: 5
---

```{r}
library(knitr)
library(rentrez)
library(pegas)
```


##  Mitochondrial DNA and Haplotypes - A Special Case

Organellar DNA has a rich history in population genetics.  In the late 1970's, John Avise, then starting his career, proposed that animal mitochondrial DNA has some unique properties that make it suitable for use in population genetic studies.  In particular

1.  It is genetically haploid.
1.  It does not recombine
2.  It is uniparentally (usually maternally) inherited.
3.  Experimental work (at the time involving restriction site analysis) showed it to be highly variable.

Fast forward to the present, and if you a keyword search on "mitochondrial" in popset returns over 15,000 hits - in fact they far and away the most frequent class of sequence sets in that database.  Note, however, that they are by and large restricted to animals - in plants, chloroplast DNA has been used successfully for similar purposes, however its lower level of variation reduces its utility somewhat.

While there is much we could say about the structure of mtDNA and its applicability to evolutionary questions, two features should be mentioned:

1.  The *coi* gene, a relatively conserved sequence, has been widely employed as a "DNA Barcode" to identify samples at the species level.
2.  The "D loop", the origin of replication, is a very A/T-rich region that is highly variable among individuals; this is an excellent sequence to use for population structure studies.

The intent here is to introduce mtDNA manipulation, so that you can consider it for further explorations.  We will start by showing how we can use it to construct a network of haplotypes and ask whether it reveals meaningful relations among individuals in a population.  We will then use it to briefly introduce BEAST, a Bayesian inference approach to making inferences about past population structure.

### An example with dogs

The data we are going to look at are from popset [322367799](http://www.ncbi.nlm.nih.gov/popset/322367799), a collection of control region sequences from various dog breeds.  The data have previously been downloaded as a FASTA file, so we can read it in as follows:

```{r}
dat.rnt <-entrez_search(db="popset",term="322367799")
dat.raw <-entrez_fetch("popset",id=dat.rnt$ids,rettype="fasta")
write(dat.raw,file="../Data/dog.fasta")
dog.dat <-read.FASTA("../Data/dog.fasta")
dog.dat
```

We need to edit the names of each sequence to something meaningful, in this case the breed.  We can use the following trick for this case (for others, another parsing method might have to be applied)

```{r}
nms <- names(dog.dat)
nms<- sapply(nms, function(x) word(x,8,9))
names(dog.dat) <- nms
dog.dat
```


As always, it is important to ensure that the sequences are aligned, which we will do with muscle (remember that the binary file must be accessible by R).

```{r}
dat.aln <-muscle(dog.dat)
```

And with that, we can visualize the alignment:

```{r}
image.DNAbin(dat.aln,cex.lab=.5)
```

We see that there is a huge gap in the middle of it.  Here's where one of the great advantages of the matrix format comes in - we can readily select the first 600 nucleotides, which are free of gaps, and use them for our subsequent analysis:

```{r}
dat.aln.sub <-dat.aln[,1:600]
image.DNAbin(dat.aln.sub,cex.lab=.5)
```

And that looks better.  Note that the names of the sequences were edited prior to loading the data as well - full original designations can be found in the popset link.

Now we are going to identify how many distinct mtDNA haploytpes are present in the sample:

```{r}
dat.hap <-haplotype(dat.aln.sub)
dat.hap
```

So among the 17 sequences in the data set, there are 12 different haplotypes.  


We can now visualize them in two ways.

#### Visualization 1.  A Tree

One of the most familiar ways to visualize relationships among aligned sequences is as a phylogenetic tree.  In this case, what we will do is to use the number of differences between pairs of species as a measure of their divergence and use the resulting matrix to generate a tree.  Note that for this we are treating all differences equally and are not taking the position of the differences into account.


```{r}
dat.dist <-dist.dna(dat.aln.sub) #calculate the distance matrix
plot(nj(dat.dist),type="phylo",cex=.8) # plot a "neighbor joining" tree
```

But in fact, while useful, tree visualization like this is not entirely appropriate for population data, as it implies ancestor-descendant relationships that may or may not exist. In fact, we should be thinking of this as a network of haplotypes, which differ by one or more bases.  

#### Visualization 2.  A Network

Another way of thinking about this is asking, given two haplotypes, how many substitutions would be required to go from one to the other.  We would then extend that logic to create a network of all 12 haplotypes that requires the fewest steps.  The code is a bit tricky, but it and the results are shown below:

```{r}
net <-haploNet(dat.hap)
fq <-attr(net,"freq")
plot(net,size=fq,threshold=0,cex=.5)
```

The size of the circles indicate the number of sequences for each haplotype (for example, the smallest circles like X indicate a haplotype that occurred only once in the sample, while the largest on - II - actually had three).  Note also that breeds are not shown - to do so would be a graphical nightmare.  Instead, we can do a little bit of munging and generate a table that provides that information






```{r}
sample.no <-attr(dat.hap,"index")


breed.by.haplo <-sapply(sample.no, function(x) rownames(dat.aln.sub)[x])
sorted <-sapply(breed.by.haplo,paste,collapse=" ")
haplo <-as.roman(1:12)
kable(data.frame(Haplotype=as.character(haplo),Breed=sorted))
```

So looking at these results, we can't say that we've learned a lot about these dog breeds.  But after all, our sample size, both in terms of haplotypes and sequenced bases, is quite small.  Nevertheless, it illustrates the potential of the approach.  

## GeOMe Data

Let' try this with GeOMe data!

First thing is to download the data:
1. Go to https://www.geome-db.org/query
2. Search for your species and marker
3. Download the CSV and the Fasta
4. Set up a project directory on your computer, with these raw data files in a folder called "data". 
  * Name them appropriately, and add "raw" to the filename. 
  * Also put the fasta file of your class sequences in this same folder with "raw" in the filename, and all sequences named "Dongsha"
  * Don't ever change these raw files!
5. Import both fasta files into a dedicated folder in Geneious, allowing it to rename the sequences with an appended number to make them unique.
6. Do a multiple alignment to combine the two fasta files.
  * Inspect the alignment to ensure it did a decent job. 
  * Trim the alignment as necessary to make all sequences the same length.
7. Export this trimmed alignment to a new fasta file with your species name and "aligned"
5. Change the names of the sequences in your fasta file to contain only the first 7 characters of the locality.
6. Import your fasta file into geneious

### Data Import
```{r}
library(geomedb)
library(stringr)
library(strataG)

#linckia<-queryFasta(marker="CO1",query="+genus:Linckia +species:laevigata")
#linckia
#write.dna(linckia,"test.fasta",format = "fasta")

pcoel<-read.FASTA("../Data/pcoelestis_aligned.fasta")


#renaming a geome file - save for posterity
# for technical reasons, pnod is a different flavor of dnabin object, so we have to use rownames() instead of names()
#rownames(pnod_aln)<-str_extract(string=rownames(pnod_aln),pattern="\\[locality = .+?\\]")
#rownames(pnod_aln)<-str_replace(string=rownames(pnod_aln),pattern="\\[locality = (.+?)\\]",replacement="\\1")
#ignore this final line - this is a unique problem to this species
#rownames(pnod_aln)<-str_replace_all(string=rownames(pnod_aln),pattern="\\\"",replacement="")

image.DNAbin(pcoel)
```



### Haplotype Network
And make a haplotype network using code from [here](https://arundurvasula.wordpress.com/2016/02/24/haplotype-networks-in-r/)
```{r}

# a little regular-expression kung-fu to chop off the numbers, leaving just the population name
pop<-gsub(names(pcoel),pattern = "_\\d+",replacement="")

d <- dist.dna(pcoel)
h <- pegas::haplotype(pcoel)
h <- sort(h, what = "label")

net <- pegas::haploNet(h)
i<-stack(setNames(attr(h, "index"), rownames(h)))
ind.hap<-table(hap=i$ind, pop=pop)

#play with scale.ratio to get appropriate branch lengths
plot(net,size=attr(net, "freq"), scale.ratio=10, pie=ind.hap,legend=F, labels=F,threshold=0, show.mutation=2)
#legend("topleft", colnames(ind.hap), col=rainbow(ncol(ind.hap)), pch=19, ncol=2)
```




### Diversity Statistics

#### Haplotypes and Haplotype Diversity
```{r}
pcoel_g<-sequence2gtypes(pcoel,strata=pop)
pcoel_g<-labelHaplotypes(pcoel_g)

ploidy(pcoel_g)

#num.alleles give you the number of haplotypes, and heterozygosity gives you haplotype diversity (i.e. heterozygosity for a haploid dataset) 

pcoel_g


```

#### Nucleotide Diversity
For this we need the pegas package, and we need to write our own function, because the nuc.div() function doesn't stratify the data by population.

```{r}
library(pegas)

stratastat<-function(x,pop=pop,fun=nuc.div){
  #this function will calculate stats for a DNAbin object (x), stratified across populations given in pop. 
  # Some functions this will work with: nuc.div(), theta.s(), tajima.test() from pegas, FusFs(), exptdHet() from strataG,
stats<-NULL
for(p in unique(pop)){
  stat<-fun(pcoel[grep(p,names(pcoel))])
  stats<-c(stats,stat)
}
names(stats)<-unique(pop)
return(stats)
}
stratastat(pcoel,pop=pop,fun=nuc.div)
stratastat(pcoel,pop=pop,fun=fusFs)
stratastat(pcoel,pop=pop,fun=tajima.test)

```
# Maps

1. Download the CSV output from GeOMe
2. Edit in Excel to add info from Dongsha (Latitude: 20.698691	Longitude: 116.726274). Save as CSV.
3. Make sure that the number of entries in the metadata file is equal to the number of sequences you have.

```{r}
library(ggmap)
pcoel_m<-read.csv("../Data/pcoel_metadata.csv")

#find the midpoint of all sampled points
samp_mean<-sapply(pcoel_m[,c("decimalLongitude","decimalLatitude")],mean)
pmap <- get_map(location = samp_mean, maptype = "satellite", source = "google",zoom=3)

pcoel_map<-ggmap(pmap) + geom_count(data = pcoel_m, mapping = aes(x = decimalLongitude, y = decimalLatitude), color="red") 

pcoel_map

```{r}
