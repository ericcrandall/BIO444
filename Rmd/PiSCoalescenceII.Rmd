---
title: 
- <h1>π and S - What do they Tell Us About Theta?</h1>
output:
  html_document:
    css: ../Chapter.css
    toc: yes
    toc_depth: 5
    code_fold: show
---

```{r}
library(knitr)
```

## Exploring Further

So, combining analysis of DNA sequence variation with coalescence theory, we see that we have two simple estimators of &theta;, one based on the number of segregating sites in the data (S) and the other, which is in fact just the mean pairwise differences, or π.  Since they are estimates of the same paramter (and are both unbiased), we might expect them to yield the same value, right?  Let's explore that further.


### A simple tree

So what we will do is to use ms to get us a very simple data set.  We will then look at the tree, first with the mutations as they were simulated, and second with the same *number* of mutations (S) but with them occurring on different branches.

#### Generate the tree

First, we will use ms to generate a tree and dataset with 6 samples and three segregating sites
```{r}
par(mfrow=c(1,1))
set.seed(123)
tr <-ms(nsam=6, nreps=1, opts=("-s 3 -T"))
plot(read.tree(text=tr),use.edge.length=FALSE)
```

### Look at the data

Now let's  see the actual gametes that gave rise to this tree
```{r}
tr.out <-read.ms.output(txt=tr) #Get data in usable form
gams <-as.data.frame(tr.out$gametes)
colnames(gams) <-c("p1","p2","p3")
kable(gams,align="l")
```

As an exercise, you should now be able to walk through the tree, remembering that the ancestral haplotype was (0 0 0) and position the mutations accordingly.  Having done that, we now want to calculate the two estimators of &theta;.

### Calculating π

Remember that we just need to take every pair of sequences, count the number of differences, and divide the sum of those differences by n(n-1)/2.  The following function will do that

```{r}
picalc <- function (gams) {
  k <-nrow(gams)
  l <-k-1
  pi <-0
  for (i in 1:l){
    for (j in 2:k){
      pi <-pi+sum(abs(gams[i,]-gams[j,]))
    }
  }
  pi <-pi/((k*(k-1))/2)
  pi
}
```
And we can plug in our results from the simulation to get
```{r}
pi.sim <-picalc(gams)
pi.sim
```
And that, of course, is our estimator of &theta;

### Estimating &theta;<sub>w</sub>

For the Watterson estimator of &theta; remember that  we need to divide S by ∑(1/k) summed over 1 to k-1
```{r}
th.w <-3/sum(1/c(1:5))
th.w
```
And we see that we get a similar, but not identical number.  So what gives?  

### Comparing the Two Estimates

Look back at what we have.  One of our two estimators, the Watterson one, is based only on S, which in the infinite sites model, is simply the total number of mutations.  **It says nothing about when and where the mutations occurred**.  π, on the other hand, involves comparison of sequences in a pairwise fashion, so we might intuitively expect that the position of the mutational events on the geneology might have an effect on it.

We can illustrate this with the tree above.  We will keep the number of segregating sites only move the location at which they occur.

We can make up a dataset as follows:


```{r}
g2 <-as.data.frame(rbind(c(0,0,0),c(1,0,0),c(0,0,0), c(0,0,0),c(0,1,0),c(0,0,1)))
colnames(g2) <-colnames(gams)
kable(g2,align="l")
```

And as you map these mutations, you will see that they all occur in the tip branches, and as a result, each mutation is represented only once in the data set, and each in a different sequence.  So now we can calculate π with our function and compare it to what we got with the original data.

```{r}
pi.2 <-picalc(g2)
pi.2
```
And we get a value of `r pi.2`, which can be compared with the value from the original data set of `r pi.sim`.  Not a huge difference, but a difference nevertheless.  And remember - the Watterson estimator is identical for the two scenarios.  So we need to explore the relationship between π and the location of mutations on the tree more closely.

## π, S, and the Site Frequency Spectrum

Remember that the site frequency spectrum simply consists of the numbers of sites that differ at 1,2, . . .n/2 among the sequences sampled.  It should be very obvious that if we take the sum of all of the classes in the SFS, what we get is S.  For π, the relationship is a bit more complicated, but with a little bit of thought, we can get to the following relationship:

π = [∑(i)(n-i)&eta;<sub>i</sub>]/((n*(n-1))/2)

where &eta;<sub>i</sub> is the number of sites in class i of the SFS.

Don't worry too much about the math of the above expression; what we want to ask is which of the classes of the SFS makes the most significant contribution to π.  To get at that, we simply have to ask when n(n-i), which is the average pairwise difference for a single site when there are i derived sequences, is maximized.  We can visualize that over the range of i=1:n, where n=10.


```{r}
n <-10
i <-c(0:10)
v <-i*(n-i)
plot(i,v,type="l")
```

If you don't want to fight with the math, then remember the analogy between &pi; at the sequence level and heterozygosity at the allelic level.  We know that heterozygosity is maximized when p=q=.5,
so the conclusion we draw here is similar - &pi; is maximized when i=n/2, which would be the case for sites in which f(0) = f(1) = .5


Based on this, look back at our two hypothetical situations.  In the first case, with mutations that divide the tree earlier in the process, we get a higher value of π than we do when they occur in tip branches, each separating only one sequence from all of the rest.  Now, as we look at the data matrix for the original simulation, we see that p2 and p3 have frequencies of (2,4), closer to that maximum than the frequencies of (1,5) that all three sites have in the second case.

### Conclusion.  

We can now see the basis for the different estimates we get for &theta; - one is simply based on mutation number, while the other incorporates the distribution of those mutations on the gene geneology.  Again, given that &theta; is a single parameter, what we have is two estimators of the same thing, so

E[π] = E[&theta;<sub>w</sub>] = &theta;

So if our estimates are different, is it significant?  And if it is significant, what do we conclude?  Before going on to the next section, you might want to view the video below, in which Mohammed Noor explores this question and introduces Tajima's D statistic.

<iframe width="100%" height="360" src="https://www.youtube.com/embed/wiyay4YMq2A" frameborder="0" allowfullscreen></iframe>